{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MKesfofhZNf4"
      },
      "source": [
        "# Analysing Deltron 3030's *Deltron 3030*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sf1Znq7pZnWp"
      },
      "source": [
        "<tr>\n",
        "    <td> <img src=\"https://logjampresents.com/wp-content/uploads/2017/06/Social-2-Deltron-3030.170907.jpg\" width=\"600\" height =\"350\"/> </td>\n",
        "\n",
        "</tr>\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BoWYvRPvcL4b"
      },
      "source": [
        "\n",
        "Del tha Funkee Homosapien often regarded as \"King of Oddball Rappers\" along with Automator, the Kool Keith and Kid Koala debuted as the supergroup Deltron 3030 with their [self-titled album](https://open.spotify.com/album/04uhhcjGVCHodMgZjXOlye?si=iiTGJm_fRwa8EM03rfVtLw). *Deltron 3030* is a rap opera concept album set in the year 3030 where corporate oligarchs suppress human rights and hip-hop. It stars a super hero Deltron-Z (or Deltron Zero) who traverses the galaxy \"supporting his secretive Earthling existence by participating in weird rap battles where one's rhymes summon psychic powers that physically damage the opponent\" ([pitchfork](https://https://pitchfork.com/reviews/albums/2272-deltron-3030/)). \n",
        "\n",
        "In this assignment, we will explore the lyrics of this space opera.\n",
        "\n",
        "\n",
        "Alternatively, if you would like to analyse a collection of texts of your own choosing (another album, set of news articles, film reviews, etc) you are most welcome to! But please modify the sub-questions as per your data, if necessary."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kDj2XgBzhQB9"
      },
      "source": [
        "##Data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx2d7mNWhHDa"
      },
      "source": [
        "The data can be found under the folder \"<span style:=\"color:darkblue\">deltron</span>\". \n",
        "\n",
        "This folder is composed of files corresponding to the various songs and their lyrics in Deltron 3030's self titled album.\n",
        "\n",
        "We suggest having a look at this folder before proceeding.\n",
        "(and giving the album a listen perhaps during analysis :)\n",
        "\n",
        "FYI: This data was acquired from [Genius](https://genius.com) (Genius Lyrics) using their API."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-QJ6eNSNiYFp"
      },
      "source": [
        "## Exercises\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Df0E9z6bigVU"
      },
      "source": [
        "We would like to look through all the lyrics of the album *Deltron 3030* and be able to understand their characteristics. \n",
        "\n",
        "Write the outputs of your findings to the file \"results.txt\", where specified.\n",
        "\n",
        "Make your results as pretty as possible, and feel free to use tabs and enumeration."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_MmnPE6ZjBIR"
      },
      "source": [
        "1. Write a function that reads through the files in a directory. \n",
        "\n",
        "    *   Read through the deltron directory and all its contents.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDntf2kiZLyx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import codecs\n",
        "\n",
        "\"\"\"Reading files from folder\"\"\"\n",
        "def ReadFile():\n",
        "  allText = []\n",
        "  for filename in os.listdir('deltron'):\n",
        "    with codecs.open(os.path.join(\"deltron\", filename),'r',\"utf_8_sig\") as f:\n",
        "      for lyrics in f.read().split('\\n'):\n",
        "        allText.append(lyrics)  \n",
        "  return('\\n'.join(allText).split('\\n')) \n",
        "\n",
        "ReadFile()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fv3kPz9mjTxc"
      },
      "source": [
        "2. Perform text normalization on the lyrics. Text normalisation should include removal of\n",
        "\n",
        "    *   neccessary punctuations\n",
        "    *   lowercasing the lyrics\n",
        "    *   try removing [function words](https://https://en.wikipedia.org/wiki/Function_word)\n",
        "\n",
        "    *   remove meta-information (remember assignment 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFq7QQMPjcZO"
      },
      "outputs": [],
      "source": [
        "def remove_punctuations(text):\n",
        "    \"\"\"Remove punctuations\"\"\"\n",
        "    remove_punctuations = [line.replace(',', '').replace('\"', '').replace('.', '').replace(\"'\", '') for line in text]\n",
        "    return remove_punctuations\n",
        "\n",
        "def convert_to_lowercase(text):\n",
        "    \"\"\"Convert to lowercase\"\"\"\n",
        "    lower_casing_text = [line.lower() for line in text]\n",
        "    return lower_casing_text\n",
        "\n",
        "def remove_function_words(text):\n",
        "    \"\"\"Remove function words\"\"\"\n",
        "    function_words = ['the', 'a', 'an', 'and', 'but', 'for', 'so', 'since', 'as', 'in', 'to', 'be', 'or', 'at', 'of', 'is', 'you', 'with', 'your', 'my', 'its', 'it']\n",
        "    remove_function_words = [line for line in text if all(word not in line.split() for word in function_words)]\n",
        "    return remove_function_words\n",
        "\n",
        "def remove_meta_information(text):\n",
        "    \"\"\"Remove parentheses\"\"\"\n",
        "    remove_meta_information = [char for line in text for split in str(line).split('[') for char in str(split).split(']')]\n",
        "    return remove_meta_information\n",
        "\n",
        "def remove_braces(text):\n",
        "    \"\"\"Remove braces\"\"\"\n",
        "    remove_braces = [char for line in text for split in str(line).split('{') for char in str(split).split('}')]\n",
        "    return remove_braces\n",
        "\n",
        "def Normalize_lyrics(text):\n",
        "    text = remove_punctuations(text)\n",
        "    text = convert_to_lowercase(text)\n",
        "    text = remove_function_words(text)\n",
        "    text = remove_meta_information(text)\n",
        "    text = remove_braces(text)\n",
        "    return text\n",
        "\n",
        "text = ReadFile()\n",
        "normalized_lyrics = Normalize_lyrics(text)\n",
        "print('\\n'.join(normalized_lyrics))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7f3oybV4ZMfl"
      },
      "source": [
        "3. Write a function that returns some statistics about the album Deltron 3030's song lyrics:\n",
        "\n",
        "    * Most frequent words\n",
        "    * Type to token ratio (unique words/words)\n",
        "    * Longest and shortests songs (by lyrics)\n",
        "    * What are the songs with the largest vocabulary and shortest vocabulary?\n",
        "    \n",
        "   Write these statistics for **every song** and for the **entire album** to a file \"results.txt\". \n",
        "   \n",
        "    * Write down your interpretation of these results in this notebook.  \n",
        "    * This is a particularly verbose album. Do you agree? Back it with some evidence.\n",
        "    * Which songs are the most verbose and is there a pattern? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NjPUvH-2wNP"
      },
      "outputs": [],
      "source": [
        "file = open('results.txt', 'w')\n",
        "\n",
        "def write_to_file(text):\n",
        "    print(text)\n",
        "    file.write(text + '\\n')\n",
        "\n",
        "def write_section_title(title):\n",
        "    write_to_file(title)\n",
        "    write_to_file('=' * len(title))\n",
        "\n",
        "def most_frequent_words(text):\n",
        "    from collections import Counter\n",
        "    split_it = text.split()\n",
        "    counter = Counter(split_it)\n",
        "    most_occur = counter.most_common(200)\n",
        "    write_section_title(\"Most frequent words ('Word', Number of repetitions)\")\n",
        "    write_to_file(str(most_occur))\n",
        "\n",
        "def unique_words(text):\n",
        "    from collections import Counter\n",
        "    split_it = text.split()\n",
        "    counter = Counter(split_it)\n",
        "    get_all_words = counter.most_common(2000)\n",
        "    unique_words = list(reversed(get_all_words))[:len(get_all_words)-1800]\n",
        "    write_section_title(\"Unique words ('Word', Number of repetitions)\")\n",
        "    write_to_file(str(unique_words))\n",
        "\n",
        "def shortest_song():\n",
        "    lenth_of_songs = []\n",
        "    shortest_song = float('inf')\n",
        "    shortest_song_name = \"\"\n",
        "    for filename in os.listdir('deltron'):\n",
        "        with codecs.open(os.path.join(\"deltron\", filename), 'r', \"utf_8_sig\") as f:\n",
        "            song_length = len(f.read())\n",
        "            lenth_of_songs.append((filename, song_length))\n",
        "            if song_length < shortest_song:\n",
        "                shortest_song = song_length\n",
        "                shortest_song_name = filename\n",
        "\n",
        "    write_section_title(\"Shortest song\")\n",
        "    write_to_file(f\"{shortest_song} {shortest_song_name}\")\n",
        "\n",
        "def longest_song():\n",
        "    lenth_of_songs = []\n",
        "    longest_song = 0\n",
        "    longest_song_name = \"\"\n",
        "    for filename in os.listdir('deltron'):\n",
        "        with codecs.open(os.path.join(\"deltron\", filename), 'r', \"utf_8_sig\") as f:\n",
        "            song_length = len(f.read())\n",
        "            lenth_of_songs.append((filename, song_length))\n",
        "            if song_length > longest_song:\n",
        "                longest_song = song_length\n",
        "                longest_song_name = filename\n",
        "\n",
        "    write_section_title(\"Longest song\")\n",
        "    write_to_file(f\"{longest_song} {longest_song_name}\")\n",
        "\n",
        "def song_with_largest_vocabulary():\n",
        "    lenth_of_voc = []\n",
        "    longest_voc = 0\n",
        "    longest_song_name = \"\"\n",
        "    for filename in os.listdir('deltron'):\n",
        "        song_text = []\n",
        "        with codecs.open(os.path.join(\"deltron\", filename), 'r', \"utf_8_sig\") as f:\n",
        "            for lyrics in f.read().split(' '):\n",
        "                song_text.append(lyrics)\n",
        "        voc_length = len(song_text)\n",
        "        lenth_of_voc.append((filename, voc_length))\n",
        "        if voc_length > longest_voc:\n",
        "            longest_voc = voc_length\n",
        "            longest_song_name = filename\n",
        "\n",
        "    write_section_title(\"Song with largest vocabulary\")\n",
        "    write_to_file(f\"{longest_voc} {longest_song_name}\")\n",
        "\n",
        "def song_with_shortest_vocabulary():\n",
        "    lenth_of_voc = []\n",
        "    shortest_voc = float('inf')\n",
        "    shortest_song_name = \"\"\n",
        "    for filename in os.listdir('deltron'):\n",
        "        song_text = []\n",
        "        with codecs.open(os.path.join(\"deltron\", filename), 'r', \"utf_8_sig\") as f:\n",
        "            for lyrics in f.read().split(' '):\n",
        "                song_text.append(lyrics)\n",
        "        voc_length = len(song_text)\n",
        "        lenth_of_voc.append((filename, voc_length))\n",
        "        if voc_length < shortest_voc:\n",
        "            shortest_voc = voc_length\n",
        "            shortest_song_name = filename\n",
        "\n",
        "    write_section_title(\"Song with shortest vocabulary\")\n",
        "    write_to_file(f\"{shortest_voc} {shortest_song_name}\")\n",
        "\n",
        "def most_frequent_words_for_one_song(text):\n",
        "    from collections import Counter\n",
        "    split_it = text.split()\n",
        "    counter = Counter(split_it)\n",
        "    most_occur = counter.most_common(5)\n",
        "    write_section_title(\"Most frequent words for one song ('Word', Number of repetitions)\")\n",
        "    write_to_file(str(most_occur))\n",
        "\n",
        "def unique_words_for_one_song(text):\n",
        "    from collections import Counter\n",
        "    split_it = text.split()\n",
        "    counter = Counter(split_it)\n",
        "    get_all_words = counter.most_common(5)\n",
        "    unique_words = list(reversed(get_all_words))\n",
        "    write_section_title(\"Unique words for one song ('Word', Number of repetitions)\")\n",
        "    write_to_file(str(unique_words))\n",
        "\n",
        "def song_length(filename):\n",
        "    with codecs.open(os.path.join(\"deltron\", filename), 'r', \"utf_8_sig\") as f:\n",
        "        song_length = len(f.read())\n",
        "        write_section_title(\"Song length\")\n",
        "        write_to_file(f\"{song_length} {filename}\")\n",
        "\n",
        "def song_vocabulary(filename):\n",
        "    song_text = []\n",
        "    with codecs.open(os.path.join(\"deltron\", filename), 'r', \"utf_8_sig\") as f:\n",
        "        for lyrics in f.read().split(' '):\n",
        "            song_text.append(lyrics)\n",
        "    voc_length = len(song_text)\n",
        "    write_section_title(\"Song vocabulary\")\n",
        "    write_to_file(f\"{voc_length} {filename}\")\n",
        "\n",
        "def read_one_file(filename):\n",
        "    all_text = []\n",
        "    with codecs.open(os.path.join(\"deltron\", filename), 'r', \"utf_8_sig\") as f:\n",
        "        for lyrics in f.read().split('\\n'):\n",
        "            all_text.append(lyrics)\n",
        "    return '\\n'.join(all_text)\n",
        "\n",
        "def statistics_for_every_song():\n",
        "    write_section_title(\"Statistics for every song\")\n",
        "    for filename in os.listdir('deltron'):\n",
        "        write_to_file(\"\\n\")\n",
        "        write_to_file(\"#####\" + filename + \"#####\")\n",
        "        write_to_file(\"\\n\")\n",
        "        text = read_one_file(filename)\n",
        "        most_frequent_words_for_one_song(text)\n",
        "        unique_words_for_one_song(text)\n",
        "        song_length(filename)\n",
        "        song_vocabulary(filename)\n",
        "\n",
        "write_to_file(\"Statistics for the entire album\")\n",
        "text = ReadFile()\n",
        "most_frequent_words(text)\n",
        "unique_words(text)\n",
        "shortest_song()\n",
        "longest_song()\n",
        "song_with_shortest_vocabulary()\n",
        "song_with_largest_vocabulary()\n",
        "statistics_for_every_song()\n",
        "file.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xiEWzcOQ1PNb"
      },
      "source": [
        "4. For all the lyrics in the album, construct a word cloud.\n",
        "\n",
        "    *   You just need to reassign the variable 'frequencies' in the code below to a dictionary of word frequencies (or Counter) in Deltron 3030/your selected corpus. Try to use an output from one of the functions above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvkn2IgH1bAn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "\n",
        "text = ReadFile()\n",
        "split_it = str(text).split()\n",
        "Counter = Counter(split_it)\n",
        "Most_occur = Counter.most_common(200)\n",
        "\n",
        "wordcloud = WordCloud()\n",
        "wordcloud.generate_from_frequencies(Most_occur)\n",
        "plt.figure()\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CtH_Individual_Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
